---
title: Day 24 - PDF-AI Functionality and Document Management
description: Implementing the PDF-AI functionality with document uploading, processing.
author: [Rajan Kumar Yadav]
date: 2024-07-04
categories: [Python, Programming]
tags: [Python, Streamlit, PDF-AI]
pin: true
math: true
mermaid: true
---

PDF-AI Functionality:
- Implemented the PDF-AI section with document uploading and processing.
- Set up Q&A generation using different models based on the uploaded PDF content.

Document Management:
- Handled document uploading and storage.
- Processed PDFs to extract text and prepare for Q&A generation.

Code Examples
```python
elif selected == "PDF-AI":
    st.title("PDF-AI")

    # Sidebar configuration
    with st.sidebar:
        st.title('PDF-AI')
        def vector_embedding(pdf_files):
            if "vectors" not in st.session_state:
                st.session_state.embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
                st.session_state.docs = []
                for pdf_file in pdf_files:
                    with open(f"./uploaded_pdfs/{pdf_file.name}", "wb") as f:
                        f.write(pdf_file.getbuffer())
                    st.session_state.docs.extend(PyPDFDirectoryLoader("./uploaded_pdfs").load()) ## Document Loading
                st.session_state.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) ## Chunk Creation
                st.session_state.final_documents = st.session_state.text_splitter.split_documents(st.session_state.docs[:20]) #splitting
                st.session_state.vectors = FAISS.from_documents(st.session_state.final_documents, st.session_state.embeddings) #vector OpenAI embeddings


        st.subheader('Document Upload')
        pdf_files = st.file_uploader("Choose PDF files", accept_multiple_files=True, type=["pdf"])
        if st.button("Documents Embedding") and pdf_files:
            if not os.path.exists("./uploaded_pdfs"):
                os.makedirs("./uploaded_pdfs")
            vector_embedding(pdf_files)
            st.write("Vector Store DB Is Ready")

    # Define the vector_embedding function
    
    # Store LLM generated responses
    if "messages" not in st.session_state.keys():
        st.session_state.messages = [{"role": "assistant", "content": "How may I assist you today?"}]

    # Display or clear chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    def clear_chat_history():
        st.session_state.messages = [{"role": "assistant", "content": "How may I assist you today?"}]
    st.sidebar.button('Clear Chat History', on_click=clear_chat_history)

    llm = ChatGroq(groq_api_key=groq_api_key, model_name="Llama3-8b-8192")

    prompt = ChatPromptTemplate.from_template(
        """
        Answer the questions based on the provided context only.
        Please provide the most accurate response based on the question.
        <context>
        {context}
        <context>
        Questions: {input}
        """
    )

    # User-provided prompt
    if prompt1 := st.chat_input("Enter your question about the documents here..."):
        st.session_state.messages.append({"role": "user", "content": prompt1})
        with st.chat_message("user"):
            st.write(prompt1)

        if "vectors" in st.session_state:
            document_chain = create_stuff_documents_chain(llm, prompt)
            retriever = st.session_state.vectors.as_retriever()
            retrieval_chain = create_retrieval_chain(retriever, document_chain)
            start = time.process_time()
            response = retrieval_chain.invoke({'input': prompt1})
            st.write("Response time:", time.process_time() - start)
            st.write(response['answer'])

            # With a streamlit expander
            with st.expander("Document Similarity Search"):
                # Find the relevant chunks
                for doc in response["context"]:
                    st.write(doc.page_content)
                    st.write("--------------------------------")
